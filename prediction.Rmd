---
title: "HUDK4051: Prediction - Comparing Trees"
author: "Gian Zlupko"
date: "4/21/2021"
output: html_document
---

In this assignment you will modeling student data using three flavors of tree algorithm: CART, C4.5 and C5.0. We will be using these algorithms to attempt to predict which students drop out of courses. Many universities have a problem with students over-enrolling in courses at the beginning of semester and then dropping most of them as the make decisions about which classes to attend. This makes it difficult to plan for the semester and allocate resources. However, schools don't want to restrict the choice of their students. One solution is to create predictions of which students are likley to drop out of which courses and use these predictions to inform semester planning. 

In this assignment we will be using the tree algorithms to build models of which students are likely to drop out of which classes. 

## Software

In order to generate our models we will need several packages. The first package you should install is [caret](https://cran.r-project.org/web/packages/caret/index.html).

There are many prediction packages available and they all have slightly different syntax. caret is a package that brings all the different algorithms under one hood using the same syntax. 

We will also be accessing an algorithm from the [Weka suite](https://www.cs.waikato.ac.nz/~ml/weka/). Weka is a collection of machine learning algorithms that have been implemented in Java and made freely available by the University of Waikato in New Zealand. To access these algorithms you will need to first install both the [Java Runtime Environment (JRE) and Java Development Kit](http://www.oracle.com/technetwork/java/javase/downloads/jre9-downloads-3848532.html) on your machine. You can then then install the [RWeka](https://cran.r-project.org/web/packages/RWeka/index.html) package within R.

**Weka requires Java and Java causes problems. If you cannot install Java and make Weka work, please follow the alternative instructions at line 121**
(Issue 1: failure to install RWeka/RWekajars, paste "sudo R CMD javareconf" into terminal and try to install again)

The last package you will need is [C50](https://cran.r-project.org/web/packages/C50/index.html).

## Libraries

```{r, echo = FALSE}
library(caret) 
library(C50) 
library(RWeka) 
library(tidyverse) 
library(kableExtra) 

```

## Data

The data comes from a university registrar's office. The code book for the variables are available in the file code-book.txt. Examine the variables and their definitions.

Upload the drop-out.csv data into R as a data frame. 

```{r}

drop_out <- data.frame(read_csv("drop-out.csv")) 

drop_out %>% 
  kbl() %>%
  kable_styling(bootstrap_options = c("striped", "hover"), full_width = F) 

head(drop_out) 


```

The next step is to separate your data set into a training set and a test set. Randomly select 25% of the students to be the test data set and leave the remaining 75% for your training data set. (Hint: each row represents an answer, not a single student.)

## Data Cleaning 

```{r}

# filter by unique students - remove duplicate IDs

set.seed(182) 

drop_out_distinct <- drop_out %>% 
  distinct(student_id, .keep_all = TRUE) 


drop_out_1 <- drop_out_distinct %>% 
  mutate(student_id = as.factor(student_id), course_id = as.factor(course_id), 
         gender = as.factor(gender), complete = factor(complete, levels  = c("no", "yes")), international = as.factor(international), 
         online = as.factor(online)) 
  

# exclude enrollment date 

drop_out_1 <- drop_out_1 %>%
  select(-c(enroll_date_time))

```

## Split Data 

```{r, warning = FALSE}


trainData <- createDataPartition(
  y = drop_out_1$complete, 
  p = 0.75, 
  list = FALSE
)


training <- drop_out_1[trainData, ]
testing <- drop_out_1[-trainData, ]

cntrl <- trainControl(method = "cv", repeats = 5) 

```



For this assignment you will be predicting the student level variable "complete". 
(Hint: make sure you understand the increments of each of your chosen variables, this will impact your tree construction)

Visualize the relationships between your chosen variables as a scatterplot matrix.  Save your image as a .pdf named scatterplot_matrix.pdf. Based on this visualization do you see any patterns of interest? Why or why not?

```{r}
library(GGally) 

View(drop_out_1)

# View correlations among predictor variabl es 
drop_out_1 %>%
  select(c(entrance_test_score, courses_taken, complete)) %>%
  ggpairs(ggplot2::aes(colour = complete))

# pair plot excluding student_ids 
my_colors <- c("#00AFBB", "#E7B800")
pairs(drop_out_1[, c(2:6)], lower.panel = NULL, 
      col = my_colors[drop_out_1$complete])
  


```

## CART Trees

You will use the [rpart package](https://cran.r-project.org/web/packages/rpart/rpart.pdf) to generate CART tree models.

Construct a classification tree that predicts complete using the caret package.

```{r}
library(caret)
library(MLmetrics) 

TRAIN1 <- training 

TRAIN2 <- TRAIN1[,c(2:9)] #Remove the student_id variable that we do not want to use in the model

#caret does not summarize the metrics we want by default so we have to modify the output
MySummary  <- function(data, lev = NULL, model = NULL){
  df <- defaultSummary(data, lev, model)
  tc <- twoClassSummary(data, lev, model)
  pr <- prSummary(data, lev, model)
  out <- c(df,tc,pr)
  out}

#Define the control elements we would like to use
ctrl <- trainControl(method = "repeatedcv", #Tell caret to perform k-fold cross validation
                repeats = 3, #Tell caret to repeat each fold three times
                classProbs = TRUE, #Calculate class probabilities
                summaryFunction = MySummary)

#Define the model
cartFit <- train(complete ~ ., #Define which variable to predict 
                data = TRAIN2, #Define the data set to train the model on
                trControl = ctrl, #Tell caret the control elements
                method = "rpart", #Define the model type
                metric = "Accuracy", #Final model choice is made according to sensitivity
                preProc = c("center", "scale")) #Center and scale the data to minimize the 

#Check the results
cartFit


```


Describe important model attribues of your tree. Do you believe it is a successful model of student performance, why/why not?

In our case, predicting true positives is key (e.g. did not complete the course) becuase we will want to design interventions to help students complete the course. Therefore we are really interested in sensitivity metric ('recall'), which examines model performance with regards to true positives. Sensitivity was .91 which isg good. 

Can you use the sensitivity and specificity metrics to calculate the F1 metric?

From a confusion matrix we could calculate F1 from the model's predicted outputs. F1 = (2TP) / (2TP + FP + FN). However, we cannnot calculate an F1 value from sensitivity and specificity as F1 is the harmonic mean of sensitivity and precision, not specificity 

Now predict results from the test data and describe important attributes of this test. Do you believe it is a successful model of student performance, why/why not?

```{r}
TEST1 <- testing 

TEST2 <- TEST1[,c(2:9)] #Remove the student_id variable that we do not want to use in the model
 
#Generate prediction using previously trained model
cartClasses <- predict(cartFit, newdata = TEST2)

#Generate model statistics
confusionMatrix(data = cartClasses, as.factor(TEST2$complete))

```


## Conditional Inference Trees

Train a Conditional Inference Tree using the `party` package on the same training data and examine your results.

```{r, warning = FALSE}

library(party) 


# Conditional Tree train 
condFit <- train(complete ~ ., #Define which variable to predict 
                data = TRAIN2, #Define the data set to train the model on
                trControl = ctrl, #Tell caret the control elements
                method = "ctree2", #Define the model type
                metric = "Accuracy", #Final model choice is made according to sensitivity
                preProc = c("center", "scale")) #Center and scale the data to minimize the 

#Check the results
condFit



```

Describe important model attribues of your tree. Do you believe it is a successful model of student performance, why/why not?

Sensitivity/recall is 0.95 for this conditional inference tree model which indicates that it is a good predictor of instances in which students are not completing the course. 



```{r}
library(partykit) 
completeCondInf <- ctree(complete ~.,  data = TRAIN2) 
print(completeCondInf) 
plot(completeCondInf) 

```

What does the plot represent? What information does this plot tell us?

Conditional inference trees use p-value tests to select input values. This plot tells us that courses has a significant relationship with course completion. In particular, the plot tells us that whether a student has taken more than one previous course significantly relates to completion. Students that have taken more than one previous course are more likely to complete the course.

Now test your new Conditional Inference model by predicting the test data and generating model fit statistics.


```{r}

# Generate predictions with conditional tree model with party package 
condFitClasses<- predict(condFit, newdata = TEST2)

#Generate model statistics
confusionMatrix(data = condFitClasses, as.factor(TEST2$complete))
```


Predicting conditional inference tree on test data using the 'partykit' package as well: 
```{r}

# Generate predictions with conditional tree model with partykit package 
condInf_fit <- predict(completeCondInf, newdata = TEST2)

#Generate model statistics
confusionMatrix(data = condInf_fit, as.factor(TEST2$complete))

```


There is an updated version of the C4.5 model called C5.0, it is implemented in the C50 package. What improvements have been made to the newer version? 


The C5.0 model extends the C4.5 model by enabling the C5.0 model to work with non-numeric data. C5.0 is typically faster to run than the C4.5 and it uses substantially less memory to run.  


Install the C50 package, train and then test the C5.0 model on the same data.

```{r}
library(C50) 

# train the C5.0 model 
C5.0_model <- C5.0(x = TRAIN2[ ,-4], 
                   y = TRAIN2$complete) 

C5.0_model
summary(C5.0_model) 

# visualize the C5.0 Model 
plot(C5.0_model) 

#Remove the student_id variable that we do not want to use in the model


#Generate prediction using previously trained model
C50_prediction <- predict(C5.0_model, newdata = TEST2)

#Generate model statistics
confusionMatrix(data = C50_prediction, as.factor(TEST2$complete))



c50_fit <- train(complete ~ ., #Define which variable to predict 
                data = TRAIN2, #Define the data set to train the model on
                trControl = ctrl, #Tell caret the control elements
                method = "C5.0", #Define the model type
                metric = "Accuracy", #Final model choice is made according to sensitivity
                preProc = c("center", "scale")) #Center and scale the data to minimize the 

#Check the results
c50_fit

```

## Compare the models

Caret allows us to compare all three models at once.

```{r}
resamps <- resamples(list(cart = cartFit, condinf = condFit, cfiveo = c50_fit))
summary(resamps)
```

What does the model summary tell us? Which model do you believe is the best?

The model comparison shows us that the tree models used in this assignment are all relatively good predictors of student completion. In selecting the model wit the best performance, we can look at the recall/sensitivity metric comparison across each tree model. The comparison shows that the conditional inference model is the best predictor of true positives (e.g. student does not complete the course), which is most important to us in this use case. 

Which variables (features) within your chosen model are important, do these features provide insights that may be useful in solving the problem of students dropping out of courses?

Courses taken is the most important feature in the models used. If this is true, the university can take meausures to ensure that students matriculate through the program and that students that are more at risk of not completing courses can receive the support that they need.  